{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import os\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enron methanol ; meter # 988291\\r\\nthis is a f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpl nom for january 9 , 2001\\r\\n( see attached...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neon retreat\\r\\nho ho ho , we ' re around to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>photoshop , windows , office . cheap . main tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>re indian springs\\r\\nthis deal is to book the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ehronline web address change\\r\\nthis message i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spring savings certificate - take 30 % off\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>looking for medication ? we ` re the best sour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>noms / actual flow for 2 / 26\\r\\nwe agree\\r\\n-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nominations for oct . 21 - 23 , 2000\\r\\n( see ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vocable % rnd - word asceticism\\r\\nvcsc - bran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>report 01405 !\\r\\nwffur attion brom est inst s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>enron / hpl actuals for august 28 , 2000\\r\\nte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vic . odin n ^ ow\\r\\nberne hotbox carnal bride...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tenaska iv july\\r\\ndarren \\r\\nplease remove th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>underpriced issue with high return on equity\\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>re first delivery - wheeler operating\\r\\nvance...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>swift - may 2001 vols\\r\\nsean ,\\r\\nfyi , check...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meter variances - ua 4 clean - up\\r\\ndaren / v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>additional recruiting\\r\\ni ' m happy to introd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fw ercot load comparison\\r\\n- - - - - original...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meter 6461 , concorde churchill\\r\\none year ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hpl nom for january 25 , 2001\\r\\n( see attache...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>re tenaska iv 10 / 00\\r\\nwe have received all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jump in to gain substantial ground immediately...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>re enron / hpl actuals for october 11 , 2000 -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>registration confirmation from spinner . com\\r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aep transition items\\r\\nattached is a brief me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>an inbound message for you has been quarantine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>re valero gas marketing ; meter # 8018 / sitar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>economize 55 % and more with your recipes\\r\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>memo from office of the chair\\r\\nthe mid - ye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>enron / hpl actuals for june 15 , 2000\\r\\ntec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>we are the best qns\\r\\nlook at this of - fers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>re  epgt\\r\\ngloria , the difference between t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>keep your immune system strong\\r\\nkeep your i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>enron / hpl actuals for january 2 , 2001\\r\\nt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>discreet cheapest prescri ^ ption dru &amp; gs on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>cheapest meds you ' ll find .\\r\\ndiscount dru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>neon lesson # 5\\r\\nplease respond to here is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>fwd  transferring today ?\\r\\nrn $ 0 by tomom ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>oxyyyyconttin no script needeeed\\r\\n{ taaabbs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>feb 12 th sale to aquila\\r\\nfyi\\r\\ndaren - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>re  hpl meter # 980074 bammel hpl d / p to tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>cleburne - tenaska iv plant\\r\\ndaren ,\\r\\ni '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>ami , , ,\\r\\nper our conversation , i would p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>5 th changes @ duke and air liquide\\r\\n- - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>imbalance gas\\r\\njust in case worse comes to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>pictures\\r\\nstreamlined denizen ajar chased\\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>mid year prc meeting\\r\\ni would like to have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>penny stocks are about timing\\r\\nnomad intern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>anomaly boys from 3881\\r\\nuosda apaproved mle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>re  meter #  1266 ; august 2000 / allocation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>slutty milf wants to meet you\\r\\ntake that !\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>fw  crosstex energy , driscoll ranch # 1 , # ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>put the 10 on the ft\\r\\nthe transport volumes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>3 / 4 / 2000 and following noms\\r\\nhpl can ' ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>calpine daily gas nomination\\r\\n&gt;\\r\\n&gt;\\r\\njul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>industrial worksheets for august 2000 activit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>important online banking alert\\r\\ndear valued...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label_num\n",
       "0     enron methanol ; meter # 988291\\r\\nthis is a f...          0\n",
       "1     hpl nom for january 9 , 2001\\r\\n( see attached...          0\n",
       "2     neon retreat\\r\\nho ho ho , we ' re around to t...          0\n",
       "3     photoshop , windows , office . cheap . main tr...          1\n",
       "4     re indian springs\\r\\nthis deal is to book the ...          0\n",
       "5     ehronline web address change\\r\\nthis message i...          0\n",
       "6     spring savings certificate - take 30 % off\\r\\n...          0\n",
       "7     looking for medication ? we ` re the best sour...          1\n",
       "8     noms / actual flow for 2 / 26\\r\\nwe agree\\r\\n-...          0\n",
       "9     nominations for oct . 21 - 23 , 2000\\r\\n( see ...          0\n",
       "10    vocable % rnd - word asceticism\\r\\nvcsc - bran...          1\n",
       "11    report 01405 !\\r\\nwffur attion brom est inst s...          1\n",
       "12    enron / hpl actuals for august 28 , 2000\\r\\nte...          0\n",
       "13    vic . odin n ^ ow\\r\\nberne hotbox carnal bride...          1\n",
       "14    tenaska iv july\\r\\ndarren \\r\\nplease remove th...          0\n",
       "15    underpriced issue with high return on equity\\r...          1\n",
       "16    re first delivery - wheeler operating\\r\\nvance...          0\n",
       "17    swift - may 2001 vols\\r\\nsean ,\\r\\nfyi , check...          0\n",
       "18    meter variances - ua 4 clean - up\\r\\ndaren / v...          0\n",
       "19    additional recruiting\\r\\ni ' m happy to introd...          0\n",
       "20    fw ercot load comparison\\r\\n- - - - - original...          0\n",
       "21    meter 6461 , concorde churchill\\r\\none year ra...          0\n",
       "22    hpl nom for january 25 , 2001\\r\\n( see attache...          0\n",
       "23    re tenaska iv 10 / 00\\r\\nwe have received all ...          0\n",
       "24    jump in to gain substantial ground immediately...          1\n",
       "25    re enron / hpl actuals for october 11 , 2000 -...          0\n",
       "26    registration confirmation from spinner . com\\r...          0\n",
       "27    aep transition items\\r\\nattached is a brief me...          0\n",
       "28    an inbound message for you has been quarantine...          0\n",
       "29    re valero gas marketing ; meter # 8018 / sitar...          0\n",
       "...                                                 ...        ...\n",
       "5141   economize 55 % and more with your recipes\\r\\n...          1\n",
       "5142   memo from office of the chair\\r\\nthe mid - ye...          0\n",
       "5143   enron / hpl actuals for june 15 , 2000\\r\\ntec...          0\n",
       "5144   we are the best qns\\r\\nlook at this of - fers...          1\n",
       "5145   re  epgt\\r\\ngloria , the difference between t...          0\n",
       "5146   keep your immune system strong\\r\\nkeep your i...          1\n",
       "5147   enron / hpl actuals for january 2 , 2001\\r\\nt...          0\n",
       "5148   discreet cheapest prescri ^ ption dru & gs on...          1\n",
       "5149   cheapest meds you ' ll find .\\r\\ndiscount dru...          1\n",
       "5150   neon lesson # 5\\r\\nplease respond to here is ...          0\n",
       "5151   fwd  transferring today ?\\r\\nrn $ 0 by tomom ...          1\n",
       "5152   oxyyyyconttin no script needeeed\\r\\n{ taaabbs...          1\n",
       "5153   feb 12 th sale to aquila\\r\\nfyi\\r\\ndaren - - ...          0\n",
       "5154   re  hpl meter # 980074 bammel hpl d / p to tr...          0\n",
       "5155   cleburne - tenaska iv plant\\r\\ndaren ,\\r\\ni '...          0\n",
       "5156   ami , , ,\\r\\nper our conversation , i would p...          0\n",
       "5157   5 th changes @ duke and air liquide\\r\\n- - - ...          0\n",
       "5158   imbalance gas\\r\\njust in case worse comes to ...          0\n",
       "5159   pictures\\r\\nstreamlined denizen ajar chased\\r...          1\n",
       "5160   mid year prc meeting\\r\\ni would like to have ...          0\n",
       "5161   penny stocks are about timing\\r\\nnomad intern...          1\n",
       "5162   anomaly boys from 3881\\r\\nuosda apaproved mle...          1\n",
       "5163   re  meter #  1266 ; august 2000 / allocation ...          0\n",
       "5164   slutty milf wants to meet you\\r\\ntake that !\\...          1\n",
       "5165   fw  crosstex energy , driscoll ranch # 1 , # ...          0\n",
       "5166   put the 10 on the ft\\r\\nthe transport volumes...          0\n",
       "5167   3 / 4 / 2000 and following noms\\r\\nhpl can ' ...          0\n",
       "5168   calpine daily gas nomination\\r\\n>\\r\\n>\\r\\njul...          0\n",
       "5169   industrial worksheets for august 2000 activit...          0\n",
       "5170   important online banking alert\\r\\ndear valued...          1\n",
       "\n",
       "[5171 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up random seed, for reproductability of randomness\n",
    "np.random.seed(18)\n",
    "### 1. Basic data preparation and first classifier\n",
    "# Import dataset\n",
    "df1 = pd.read_csv(\"E:/Desktop old/RM/NEW RESEARCH/spam_ham_dataset.csv\")\n",
    "\n",
    "df1 = df1[['text', 'label_num']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of empty lines\n",
    "df1 = df1[df1.text.isna() == False]\n",
    "length_df1 = len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sublist of original df1, contains # lines picked at random, out of 20671 possible\n",
    "random_indexes = list(np.random.choice(length_df1 - 2, 3000, replace=False))\n",
    "df1 = df1.iloc[random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function dissects text i, attributes polarity scores, positive/negative/neutral, polarity or not, and subject\n",
    "def sentiment_analyzer(dataframe):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    scores = [sid.polarity_scores(i) for i in dataframe.text]\n",
    "    compounds = np.array([i['compound'] for i in scores], dtype='float32')\n",
    "    abs_compounds = np.array([np.sqrt(i ** 2) for i in compounds], dtype='float32')\n",
    "    negs = np.array([i['neg'] for i in scores], dtype='float32')\n",
    "    poss = np.array([i['pos'] for i in scores], dtype='float32')\n",
    "    neus = np.array([i['neu'] for i in scores], dtype='float32')\n",
    "    sent = dataframe['text'].apply(lambda x: TextBlob(x).sentiment)\n",
    "    pol = np.array([s[0] for s in sent], dtype='float32')\n",
    "    abs_pol = np.array([np.sqrt(i ** 2) for i in pol], dtype='float32')\n",
    "    subj = np.array([s[1] for s in sent], dtype='float32')\n",
    "\n",
    "    return compounds, abs_compounds, negs, poss, neus, sent, pol, abs_pol, subj\n",
    "\n",
    "\n",
    "compounds, abs_compounds, negs, poss, neus, sent, pol, abs_pol, subj = sentiment_analyzer(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns to df1, matching them with newly created variables\n",
    "df1['compounds'] = compounds\n",
    "df1['abs_compounds'] = abs_compounds\n",
    "df1['negs'] = negs\n",
    "df1['neus'] = neus\n",
    "df1['poss'] = poss\n",
    "df1['pol'] = pol\n",
    "df1['abs_pol'] = abs_pol\n",
    "df1['subj'] = subj\n",
    "\n",
    "X = df1[['compounds', 'negs', 'neus', 'poss', 'pol', 'subj']]\n",
    "y = df1['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748 0.4220183486238532\n"
     ]
    }
   ],
   "source": [
    "# First classifier\n",
    "lrxtrain, lrxtest, lrytrain, lrytest = train_test_split(X, y)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(lrxtrain, lrytrain)\n",
    "lrpreds = lr.predict(lrxtest)\n",
    "accuracy = accuracy_score(lrytest, lrpreds)\n",
    "f1 = f1_score(lrytest, lrpreds)\n",
    "# First attempt gives accuracy and f1 score of (0.748, 0.422)\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = df1[['text', 'compounds', 'abs_compounds', 'negs', 'neus', 'poss', 'pol', 'abs_pol', 'subj']]\n",
    "y_values = df1['label_num']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_values, y_values,test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=998, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2. Improving our classifier\n",
    "\n",
    "# Cleans article from numbers, capital letters, punctuation and spaces for better classifier results\n",
    "def clean_article(article):\n",
    "    art = re.sub(\"[^A-Za-z0-9' ]\", '', str(article))\n",
    "    art2 = re.sub(\"[( ' )(' )( ')]\", ' ', str(art))\n",
    "    art3 = re.sub(\"\\s[A-Za-z]\\s\", ' ', str(art2))\n",
    "    return art3.lower()\n",
    "# Stop_words will ignore common english words which are noise (the / a / an / etc.)\n",
    "# Max_df / min_df : ignore words which frequencies are above/under those thresholds\n",
    "bow = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=998, max_df=1.0, min_df=1, binary=False)\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = bow.fit_transform(xtrain.text)\n",
    "test_data = bow.transform(xtest.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '00 pm', '000', '000 enron', '000 hpl', '000 mmbtu', '01', '02',\n",
       "       '03', '04',\n",
       "       ...\n",
       "       'wynne', 'wynne hou', 'xls', 'xls hplno', 'xp', 'year', 'years',\n",
       "       'young', 'zero', 'zone'],\n",
       "      dtype='object', length=998)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain = pd.DataFrame(training_data.toarray())\n",
    "dftrain.columns = bow.get_feature_names()\n",
    "dftrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '00 pm', '000', '000 enron', '000 hpl', '000 mmbtu', '01', '02',\n",
       "       '03', '04',\n",
       "       ...\n",
       "       'wynne', 'wynne hou', 'xls', 'xls hplno', 'xp', 'year', 'years',\n",
       "       'young', 'zero', 'zone'],\n",
       "      dtype='object', length=998)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = pd.DataFrame(test_data.toarray())\n",
    "dftest.columns = bow.get_feature_names()\n",
    "dftest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706666666666667 0.9481132075471698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#improvising the model\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(dftrain, ytrain)\n",
    "lr2_preds = lr2.predict(dftest)\n",
    "accuracy = accuracy_score(ytest, lr2_preds)\n",
    "f1 = f1_score(ytest, lr2_preds)\n",
    "# improvised accuracy is (0.9746,0.9574)\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(dftrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_pred.predict(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0 89.79591836734694\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest,a)*100\n",
    "f1score = f1_score(ytest,a)*100\n",
    "print(accuracy,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 99.86666666666667\n",
      "Testing accuracy is: 93.60000000000001\n",
      "f1score is: 91.86962491869626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(dftrain, ytrain)\n",
    "train_acc = clf.score(dftrain, ytrain)*100 # mean acc on train data\n",
    "test_acc = clf.score(dftest, ytest)*100 # mean acc on test data\n",
    "y_pred = clf.predict(dftest) # make prediction\n",
    "print(\"Training accuracy is:\", train_acc )\n",
    "print(\"Testing accuracy is:\", test_acc)\n",
    "Tree_f1 = f1_score(ytest, y_pred, average=\"macro\")*100\n",
    "print(\"f1score is:\", Tree_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 99.73333333333333\n",
      "Testing accuracy is: 96.8\n",
      "f1score is: 95.97225330051467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Random Forest\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(dftrain,ytrain)\n",
    "train_acc = clf.score(dftrain, ytrain)*100 # mean acc on train data\n",
    "test_acc = clf.score(dftest, ytest)*100 # mean acc on test data\n",
    "y_pred = clf.predict(dftest) # make prediction\n",
    "print(\"Training accuracy is:\", train_acc )\n",
    "print(\"Testing accuracy is:\", test_acc)\n",
    "RandomForest_f1 = f1_score(ytest, y_pred, average=\"macro\")*100\n",
    "print(\"f1score is:\",RandomForest_f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srinivas\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.92829\tvalidation_0-error:0.14400\tvalidation_0-error@0.6:0.18800\n",
      "[1]\tvalidation_0-auc:0.94625\tvalidation_0-error:0.10800\tvalidation_0-error@0.6:0.18267\n",
      "[2]\tvalidation_0-auc:0.96851\tvalidation_0-error:0.06667\tvalidation_0-error@0.6:0.06933\n",
      "[3]\tvalidation_0-auc:0.97420\tvalidation_0-error:0.06933\tvalidation_0-error@0.6:0.05733\n",
      "[4]\tvalidation_0-auc:0.97531\tvalidation_0-error:0.08800\tvalidation_0-error@0.6:0.05467\n",
      "[5]\tvalidation_0-auc:0.98153\tvalidation_0-error:0.04800\tvalidation_0-error@0.6:0.05067\n",
      "[6]\tvalidation_0-auc:0.98298\tvalidation_0-error:0.06133\tvalidation_0-error@0.6:0.04933\n",
      "[7]\tvalidation_0-auc:0.98388\tvalidation_0-error:0.05733\tvalidation_0-error@0.6:0.04533\n",
      "[8]\tvalidation_0-auc:0.98440\tvalidation_0-error:0.05067\tvalidation_0-error@0.6:0.04800\n",
      "[9]\tvalidation_0-auc:0.98412\tvalidation_0-error:0.04533\tvalidation_0-error@0.6:0.04667\n",
      "[10]\tvalidation_0-auc:0.98524\tvalidation_0-error:0.04933\tvalidation_0-error@0.6:0.04667\n",
      "[11]\tvalidation_0-auc:0.98621\tvalidation_0-error:0.04933\tvalidation_0-error@0.6:0.04267\n",
      "[12]\tvalidation_0-auc:0.98732\tvalidation_0-error:0.04533\tvalidation_0-error@0.6:0.04133\n",
      "[13]\tvalidation_0-auc:0.98792\tvalidation_0-error:0.04667\tvalidation_0-error@0.6:0.04133\n",
      "[14]\tvalidation_0-auc:0.98918\tvalidation_0-error:0.04400\tvalidation_0-error@0.6:0.04000\n",
      "[15]\tvalidation_0-auc:0.98894\tvalidation_0-error:0.04533\tvalidation_0-error@0.6:0.04133\n",
      "[16]\tvalidation_0-auc:0.98929\tvalidation_0-error:0.04533\tvalidation_0-error@0.6:0.04133\n",
      "[17]\tvalidation_0-auc:0.98994\tvalidation_0-error:0.04400\tvalidation_0-error@0.6:0.04133\n",
      "[18]\tvalidation_0-auc:0.99028\tvalidation_0-error:0.04400\tvalidation_0-error@0.6:0.04267\n",
      "[19]\tvalidation_0-auc:0.99060\tvalidation_0-error:0.04400\tvalidation_0-error@0.6:0.04000\n",
      "[20]\tvalidation_0-auc:0.99162\tvalidation_0-error:0.04267\tvalidation_0-error@0.6:0.03867\n",
      "[21]\tvalidation_0-auc:0.99182\tvalidation_0-error:0.04133\tvalidation_0-error@0.6:0.03867\n",
      "[22]\tvalidation_0-auc:0.99236\tvalidation_0-error:0.04133\tvalidation_0-error@0.6:0.03600\n",
      "[23]\tvalidation_0-auc:0.99236\tvalidation_0-error:0.04000\tvalidation_0-error@0.6:0.03600\n",
      "[24]\tvalidation_0-auc:0.99225\tvalidation_0-error:0.04133\tvalidation_0-error@0.6:0.03600\n",
      "[25]\tvalidation_0-auc:0.99221\tvalidation_0-error:0.04000\tvalidation_0-error@0.6:0.03733\n",
      "[26]\tvalidation_0-auc:0.99231\tvalidation_0-error:0.04000\tvalidation_0-error@0.6:0.04000\n",
      "[27]\tvalidation_0-auc:0.99243\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.04000\n",
      "[28]\tvalidation_0-auc:0.99260\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.03733\n",
      "[29]\tvalidation_0-auc:0.99293\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.03733\n",
      "[30]\tvalidation_0-auc:0.99315\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.03600\n",
      "[31]\tvalidation_0-auc:0.99354\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.03600\n",
      "[32]\tvalidation_0-auc:0.99370\tvalidation_0-error:0.03867\tvalidation_0-error@0.6:0.03600\n",
      "[33]\tvalidation_0-auc:0.99358\tvalidation_0-error:0.03733\tvalidation_0-error@0.6:0.03467\n",
      "[34]\tvalidation_0-auc:0.99367\tvalidation_0-error:0.03733\tvalidation_0-error@0.6:0.03333\n",
      "[35]\tvalidation_0-auc:0.99384\tvalidation_0-error:0.03600\tvalidation_0-error@0.6:0.03200\n",
      "[36]\tvalidation_0-auc:0.99362\tvalidation_0-error:0.03733\tvalidation_0-error@0.6:0.03333\n",
      "[37]\tvalidation_0-auc:0.99416\tvalidation_0-error:0.03600\tvalidation_0-error@0.6:0.03067\n",
      "[38]\tvalidation_0-auc:0.99419\tvalidation_0-error:0.03733\tvalidation_0-error@0.6:0.02933\n",
      "[39]\tvalidation_0-auc:0.99409\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02667\n",
      "[40]\tvalidation_0-auc:0.99403\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02667\n",
      "[41]\tvalidation_0-auc:0.99420\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.03067\n",
      "[42]\tvalidation_0-auc:0.99418\tvalidation_0-error:0.03600\tvalidation_0-error@0.6:0.02667\n",
      "[43]\tvalidation_0-auc:0.99415\tvalidation_0-error:0.03600\tvalidation_0-error@0.6:0.03067\n",
      "[44]\tvalidation_0-auc:0.99383\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02667\n",
      "[45]\tvalidation_0-auc:0.99402\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02667\n",
      "[46]\tvalidation_0-auc:0.99385\tvalidation_0-error:0.03600\tvalidation_0-error@0.6:0.02667\n",
      "[47]\tvalidation_0-auc:0.99385\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02800\n",
      "[48]\tvalidation_0-auc:0.99387\tvalidation_0-error:0.03467\tvalidation_0-error@0.6:0.02533\n",
      "[49]\tvalidation_0-auc:0.99403\tvalidation_0-error:0.03333\tvalidation_0-error@0.6:0.02533\n",
      "[50]\tvalidation_0-auc:0.99412\tvalidation_0-error:0.03333\tvalidation_0-error@0.6:0.02667\n",
      "[51]\tvalidation_0-auc:0.99415\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02533\n",
      "[52]\tvalidation_0-auc:0.99410\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02667\n",
      "[53]\tvalidation_0-auc:0.99413\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02667\n",
      "[54]\tvalidation_0-auc:0.99409\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[55]\tvalidation_0-auc:0.99418\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[56]\tvalidation_0-auc:0.99442\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[57]\tvalidation_0-auc:0.99445\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[58]\tvalidation_0-auc:0.99439\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[59]\tvalidation_0-auc:0.99422\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02933\n",
      "[60]\tvalidation_0-auc:0.99433\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[61]\tvalidation_0-auc:0.99431\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[62]\tvalidation_0-auc:0.99436\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[63]\tvalidation_0-auc:0.99444\tvalidation_0-error:0.03067\tvalidation_0-error@0.6:0.02800\n",
      "[64]\tvalidation_0-auc:0.99494\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[65]\tvalidation_0-auc:0.99498\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[66]\tvalidation_0-auc:0.99494\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[67]\tvalidation_0-auc:0.99498\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[68]\tvalidation_0-auc:0.99490\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[69]\tvalidation_0-auc:0.99494\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[70]\tvalidation_0-auc:0.99465\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[71]\tvalidation_0-auc:0.99483\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[72]\tvalidation_0-auc:0.99469\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[73]\tvalidation_0-auc:0.99443\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[74]\tvalidation_0-auc:0.99442\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[75]\tvalidation_0-auc:0.99454\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02667\n",
      "[76]\tvalidation_0-auc:0.99452\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[77]\tvalidation_0-auc:0.99458\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02667\n",
      "[78]\tvalidation_0-auc:0.99475\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02533\n",
      "[79]\tvalidation_0-auc:0.99482\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02400\n",
      "[80]\tvalidation_0-auc:0.99498\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02400\n",
      "[81]\tvalidation_0-auc:0.99503\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02400\n",
      "[82]\tvalidation_0-auc:0.99510\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02533\n",
      "[83]\tvalidation_0-auc:0.99519\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02667\n",
      "[84]\tvalidation_0-auc:0.99516\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02800\n",
      "[85]\tvalidation_0-auc:0.99503\tvalidation_0-error:0.02800\tvalidation_0-error@0.6:0.02800\n",
      "[86]\tvalidation_0-auc:0.99511\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[87]\tvalidation_0-auc:0.99505\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[88]\tvalidation_0-auc:0.99515\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[89]\tvalidation_0-auc:0.99506\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[90]\tvalidation_0-auc:0.99490\tvalidation_0-error:0.02933\tvalidation_0-error@0.6:0.02800\n",
      "[91]\tvalidation_0-auc:0.99495\tvalidation_0-error:0.03067\tvalidation_0-error@0.6:0.02933\n",
      "[92]\tvalidation_0-auc:0.99493\tvalidation_0-error:0.03067\tvalidation_0-error@0.6:0.02933\n",
      "[93]\tvalidation_0-auc:0.99483\tvalidation_0-error:0.03067\tvalidation_0-error@0.6:0.02933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94]\tvalidation_0-auc:0.99473\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "[95]\tvalidation_0-auc:0.99476\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "[96]\tvalidation_0-auc:0.99478\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "[97]\tvalidation_0-auc:0.99474\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "[98]\tvalidation_0-auc:0.99482\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "[99]\tvalidation_0-auc:0.99482\tvalidation_0-error:0.03200\tvalidation_0-error@0.6:0.02933\n",
      "96.8 94.23076923076923\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=100, random_state=50, eval_metric=[\"auc\", \"error\", \"error@0.6\"])\n",
    "xgb_model.fit(dftrain, ytrain, eval_set=[(dftest, ytest)])\n",
    "\n",
    "y_pred = xgb_model.predict(dftest)\n",
    "accuracy = accuracy_score(ytest,y_pred)*100\n",
    "f1score = f1_score(ytest,y_pred)*100\n",
    "print(accuracy,f1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
